{
    "collab_server" : "",
    "contents" : "\nlibrary(data.table)\n\n#load data\nload('data_result1/person.state.d.RData')\nload('data_result1/locations.RData')\nnetwork = readRDS('data_exec/network.RDS')\ne=network$e\nn=network$n\n\n#model definition\nAgents = c(1:ncol(person.state.d))\nTime = c(1:nrow(person.state.d))\nActions = locations\nStates = locations\nNumAgents = length(Agents)\nNumTime = length(Time)\nNumActions = length(Actions)\nNumStates = length(States)\n\n#functions\nLocation <- function(events,network) {\n  types <- as.character(levels(events$activity.start$type))\n  links <- rownames(network$e)\n  locations <- c(types,links)\n  return(locations)\n}\n\nlappend <- function (lst, ...){\n  lst <- c(lst, list(...))\n  return(lst)\n}\n\nPolicyFunction <- function(person.state.d,locations, possible_actions, trunc, SmallProb, SmallProb_offset,info_network) {\n  action_list <- list()\n  for (i in c(1:length(locations))) {\n    from <- which(possible_actions[,1]==i)\n    action_list <- lappend(action_list,possible_actions[from,2])\n  }\n  \n  Ppolicy <- list()\n  policy_all <- list()\n  policy_truc <- rep(list(list()),trunc)\n  for(i in c(1:length(locations))) {\n    policy_all <- lappend(policy_all,array(0,dim=length(action_list[[i]])))\n    policy_truc <- lapply(policy_truc, function(x) lappend(x,array(0,dim=length(action_list[[i]]))))\n  }\n  for (i in c(1:(nrow(person.state.d)-1))) {\n    if (i %% 100 == 0)\n      print(i/100)\n    policy_tmp1 <- table(factor(person.state.d[i,],levels=locations), factor(person.state.d[i+1,],levels=locations))\n    policy_tmp2 <- policy_tmp1[possible_actions]\n    policy_tmp3 <- list()\n    for (j in c(1:length(locations))) {\n      from <- which(possible_actions[,1]==j)\n      policy_tmp3 <- lappend(policy_tmp3,policy_tmp2[from])\n    }\n    policy_all <- Map('+',policy_all,policy_tmp3)\n    policy_truc[[ceiling(i/(nrow(person.state.d)/trunc))]] <- Map('+',policy_truc[[ceiling(i/(nrow(person.state.d)/trunc))]],policy_tmp3)\n  }\n  \n  policy_truc <- lapply(policy_truc,function(x) Map('+',x,Map('+',SmallProb_offset,Map('*',policy_all,SmallProb/trunc))))\n  policy_truc <- lapply(policy_truc,function(x) lapply(x,function(y) y/sum(y)))\n  \n  Pmoveout <- 1/info_network$info_road$TimeMoveOut\n  Ptransit = c(0.1,0.1,Pmoveout)\n  \n  #policy_truc <- lapply(policy_truc,function(x) lapply(1:length(x),function(n) {\n  #  tmp_x = x[[n]]\n  #  tmp_go = tmp_x[-1]/Ptransit[n]\n  #  tmp_left = pmax(1 - sum(tmp_go),0.1)\n  #  tmp_y = c(tmp_left,tmp_go)\n  #  tmp_y/sum(tmp_y)\n  #}))\n  \n  # to be changed: whether we need this?\n  policy_truc <- lapply(policy_truc,function(x) Map('+',x,SmallProb_offset))\n  # to be deleted: uniform distribution initial policy\n  #policy_truc <- lapply(policy_truc,function(x) lapply(x,function(y) y+10))\n  policy_truc <- lapply(policy_truc,function(x) lapply(x,function(y) y/sum(y)))\n  #policy_truc <- lapply(policy_truc,function(x) lapply(x,function(y) matrix(rep(y,each=max.person[[1]]+1),byrow = F,nrow = max.person[[1]]+1)))\n  \n  for (i in c(1:(nrow(person.state.d)-1))) {\n    #Ppolicy <- lappend(Ppolicy,policy_init)\n    Ppolicy <- lappend(Ppolicy,policy_truc[[ceiling(i/(nrow(person.state.d)/trunc))]])\n  }\n  \n  return(list(Ppolicy=Ppolicy,WorldModel=policy_truc,action_list=action_list))\n}\n\nLocationInOutFunction <- function(locations, possible_actions) {\n  locout <- list()\n  locin <- list()\n  for (i in c(1:length(locations))) {\n    from <- which(possible_actions[,1]==i)\n    to <- which(possible_actions[,2]==i)\n    locout <- lappend(locout,possible_actions[from[-1],2])\n    locin <- lappend(locin,possible_actions[to[-1],1])\n  }\n  return(list(locout=locout,locin=locin))\n}\n\nPossibleActionFunction <- function(network) {\n  e = network$e\n  S = matrix(0,nrow=25,ncol=43)\n  inx = 1\n  for(i in 1:length(e$from)){\n    #print(i)\n    sinto = as.integer(as.character(e$to[i]))\n    for(j in 1:length(e$from)){\n      if (sinto == e$from[j]){\n        S[i+2,inx] = -1\n        S[j+2,inx] = 1\n        inx = inx + 1\n      }\n    }\n  }\n  # 31 events before, now handle home and work case \n  home = 2 # node value\n  work = 13 # node value\n  for(i in 1:length(e$from)){\n    sinfrom = as.integer(as.character(e$from[i]))\n    sinto = as.integer(as.character(e$to[i]))\n    if (sinto == home){  # enter home\n      S[i+2,inx] = -1\n      S[1,inx] = 1\n      inx = inx + 1\n    }\n    if (sinfrom == home){  # leave home\n      S[1,inx] = -1\n      S[i+2,inx] = 1\n      inx = inx + 1\n    }\n    if (sinto == work){  # enter work\n      S[i+2,inx] = -1\n      S[2,inx] = 1\n      inx = inx + 1\n    }\n    if (sinfrom == work){  # leave work\n      S[2,inx] = -1\n      S[i+2,inx] = 1\n      inx = inx + 1\n    }\n  }\n  possible_actions <- cbind(which(S==-1,arr.ind = TRUE)[,1],which(S==1,arr.ind = TRUE)[,1])\n  #facility_stay <- array(c(1,2,1,2),dim=c(2,2))\n  action_stay <- array(c(1:nrow(S),1:nrow(S)),dim=c(nrow(S),2))\n  \n  possible_actions <- rbind(action_stay,possible_actions)\n  return(possible_actions)\n}\n\nTransitFunction <- function(NumStatesFrom,NumActions,NumStatesTo) {\n  Ptransit <- array(0,dim=c(NumStatesFrom,NumActions,NumStatesTo))\n  for (i in c(1:nrow(Ptransit))) {\n    Ptransit[i,,] <- diag(NumActions)\n  }\n  return(Ptransit)\n}\n\n# 2000 t0 50 people differs here, to be changed\nRoadLoadFunction <- function(network,scale_factor) {\n  Roadload <- array(0,dim=nrow(network$e))\n  Roadload <- as.numeric(as.character(network$e$length))/as.numeric(as.character(network$e$freespeed)) * (as.numeric(as.character(network$e$capacity))/3600*scale_factor) * as.numeric(as.character(network$e$lanes)) #* scale_factor\n  \n  TimeMoveOut <- array(0,dim=nrow(network$e))\n  TimeMoveOut <- as.numeric(as.character(network$e$length))/as.numeric(as.character(network$e$freespeed))/60\n  \n  return(list(Roadload=Roadload,TimeMoveOut=TimeMoveOut))\n}\n\nAgentGoals <- function(person.state.d,groups,locations,info_network) {\n  goal_agents <- array(0,dim=c(nrow(person.state.d),length(groups)))\n  for(i in c(1:length(groups))) {\n    xt_real <- t(apply(person.state.d[,groups[[i]]],1,function(x) table(factor(x, levels=locations))))\n    goal_agents[,i] <- apply(xt_real,1,function(x) which.max(x[info_network$facility]))\n  }\n  # 8-5\n  goal_agents[(8*60):(17*60),] <- 2\n  goal_agents[-((8*60):(17*60)),] <- 1\n  return(goal_agents)\n}\n\n#constructing prerequisite matrices\nif (TRUE) {\n  SmallProb = 0.02\n  # to be changed, whether we need this?\n  SmallProb_offset = 1e-6\n  trunc = 4\n  #locations = Location(events,network)\n  \n  home = data.frame(begin=16,end=8,typ.dur=16)\n  work = data.frame(begin=8,end=16,typ.dur=8)\n  info_facility = as.data.frame(matrix(c(home,work),ncol=3,byrow = TRUE),row.names = c('home','work'))\n  colnames(info_facility) = c('begin','end','typ.dur')\n  Roadload = RoadLoadFunction(network,400/2000)\n  possible_actions = PossibleActionFunction(network)\n  facility = c(1,2)\n  link = c(3:25)\n  info_network = list(info_facility=info_facility,info_road=Roadload,facility=facility,link=link)\n  groups = list(c(1:20),c(21:30),c(31:50))\n  goal_agents = AgentGoals(person.state.d,groups,locations,info_network)\n  Locationinout = LocationInOutFunction(locations, possible_actions)\n  locin = Locationinout$locin\n  locout = Locationinout$locout\n  \n  #constructing ppolicy,ptransit,preward\n  Ppolicy = PolicyFunction(person.state.d,locations, possible_actions, trunc,SmallProb,SmallProb_offset,info_network)\n  #Ptransit = TransitFunction(NumStates,NumActions,NumStates)\n  PpolicyUpdate = Ppolicy$Ppolicy\n  WorldModel = Ppolicy$WorldModel\n  #PpolicyUpdate = rapply( PpolicyUpdate, f=function(x) ifelse(is.nan(x),0,x), how=\"replace\" ) \n  action_list = Ppolicy$action_list\n  \n  #save(Ppolicy,file = 'data_exec/Ppolicy.RData')\n  #save(Ptransit,file='data_result3/Ptransit.RData')\n  save(info_network,file='data_result3/info_network.RData')\n  save(goal_agents,file='data_result3/goal_agents.RData')\n  saveRDS(PpolicyUpdate,file='data_result3/PpolicyUpdate.RDS')\n  save(possible_actions,file='data_result3/possible_actions.RData')\n  save(action_list,file = 'data_result3/action_list.RData')\n  save(locin,file = 'data_result3/locin.RData')\n  save(locout,file = 'data_result3/locout.RData')\n  save(groups,file = 'data_result3/groups.RData')\n  save(WorldModel,file='data_result3/WorldModel.RData')\n}\n\nif (TRUE) {\n  load('data_result3/info_network.RData')\n  load('data_result3/goal_agents.RData')\n  PpolicyUpdate = readRDS('data_result3/PpolicyUpdate.RDS')\n  load('data_result3/possible_actions.RData')\n  load('data_result3/action_list.RData')\n  load('data_result3/WorldModel.RData')\n  load('data_result2/inference_1_synthtown.RData')\n  \n  #la_TMt\n  #lalbTmt = ComputelalbTmt(loc.d,locations,max.person,action_list,PpolicyUpdate)\n  if (TRUE) {\n    # normal\n    la_Tmt = la\n    lb_Tmt = lb\n    attr(la_Tmt,'t') =attr(lb_Tmt,'t') = 1:nrow(loc.d)\n    attr(la_Tmt,'c')=\"a\"\n    attr(lb_Tmt,'c')=\"b\"\n    remove(list = setdiff(ls(),c('lg','loc.d','rate_in',\n                                 'rate_out','rate_in_f','rate_out_f',\n                                 'loc_in','loc_out','loc_in_f','loc_out_f',\n                                 'la_Tmt','lb_Tmt','m','m.time','max.person','observable_nominal',\n                                 'unobservable','observable','alloc','getSlice','locations',\n                                 'Xt_real','person.state.d',\n                                 'info_network','PpolicyUpdate','goal_agents',\n                                 'possible_actions','action_list','locin','locout',\n                                 'groups','WorldModel'\n    )))\n  }\n  \n  save.image(file = \"data_result3/inference_1_synthtown.RData\")\n  \n}\n\n\n#topython\nif (FALSE) {\n  #action_list_1 = unlist(sapply(1:25,function(n) rep(n,length(action_list[[n]][-1]))))\n  #action_list_2 = cbind(action_list_1,unlist(lapply(action_list,function(n) n[-1])))\n  #actions = sapply(1:25,function(n) length(action_list[[n]][-1]))\n  \n  #write.table(actions,\"topython//actions.csv\",sep=\",\",row.names=F,col.names=F)\n  #write.table(action_list_2,\"topython//action_list.csv\",sep=\",\",row.names=F,col.names=F)\n  write.table(info_network$info_road,\"topython//info_road.csv\",sep=\",\",row.names=F,col.names=F)\n  write.table(possible_actions,\"topython//possible_actions.csv\",sep=\",\",row.names=F,col.names=F)\n  policy_init = output <- matrix(unlist(lapply(PpolicyUpdate,function(n) lapply(n,function(m) m[-1]))), ncol = 43, byrow = TRUE)\n  write.table(policy_init,\"topython//policy_init.csv\",sep=\",\",row.names=F,col.names=F)\n  \n  person.state.d <- matrix(as.numeric(factor(person.state.d, levels=c('h','w',1:23))), nrow=nrow(person.state.d))\n  write.table(person.state.d,\"topython//person_state_d.csv\",sep=\",\",row.names=F,col.names=F)\n  write.table(Xt_real,\"topython//xt_real.csv\",sep=\",\",row.names=F,col.names=F)\n}\n\n#server collecting data\n#../target/matsim-inference-1.0-SNAPSHOT-jar-with-dependencies.jar\n#~/MATSIM/matsim/matsim/target/matsim-0.7.0-SNAPSHOT-jar-with-dependencies.jar\n#~/transportation/matsim-R/target/matsim-inference-1.0-SNAPSHOT-jar-with-dependencies.jar\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1525960642804.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3471128706",
    "id" : "6CEB0F32",
    "lastKnownWriteTime" : 1525960806,
    "last_content_update" : 1525960806657,
    "path" : "~/Documents/R/RL_VI_2018_NIPS/vi_prep3_50_a=v/prep3_1_2_vi_rl_links.R",
    "project_path" : "prep3_1_2_vi_rl_links.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}