{
    "collab_server" : "",
    "contents" : "\nlibrary('Matrix')\nrequire('TTR')\nrequire('igraph')\nrequire('survey')\nrequire('grr')\nrequire('RcppEigen')\nrequire('Rcpp')\nlibrary(ggplot2)\nsourceCpp(\"rcpp_pf_location.cpp\")\n\nload(\"data_exec/Xt_real.RData\")\nload('data_exec/obs.matrix.RData')\nload('data_prep/person.state.d.RData')\nload('data_exec/Yt.RData')\nload('data_prep/locations.RData')\nload('data_exec/info_facility.RData')\nnetwork = readRDS('network.RDS')\nload('data_exec/Roadload.RData')\nPpolicy = readRDS('data_exec/PpolicyUpdate.RDS')\nload('data_exec/possible_actions.RData')\nload('data_prep/td.RData')\nload('data_exec/action_list.RData')\nload('data_prep/facility_length.RData')\nload('data_exec/facility_index.RData')\nXt_real = matrix(as.numeric(factor(Xt_real, levels=locations)), nrow=nrow(Xt_real))\nXt_est = array(0,dim=dim(Xt_real))\nYt = matrix(as.numeric(factor(Yt, levels=locations)), nrow=nrow(Yt))\nif (FALSE) {\n  Yt_vehicles = t(apply(Yt,1,function(x) table(factor(x, levels=c(1:length(locations)) ))))\n  save(Yt_vehicles,file='data_exec/Yt_vehicles.RData')\n  Xt_real_1 = t(apply(Xt_real,1,function(x) table(factor(x, levels=c(1:length(locations)) ))))\n  save(Xt_real_1,file='data_exec/Xt_real_1.RData')\n}\nload('data_exec/Xt_real_1.RData')\nload('data_exec/Yt_vehicles.RData')\nload('data_exec/policy_template.RData')\npolicy_origin = Ppolicy\nsystem.reward.updated = list()\n\n#model\nTEST = 0\nAgents = c(1:ncol(person.state.d))\nTime = c(1:nrow(person.state.d))\nActions = locations\nStates = locations\nNumAgents = length(Agents)\nNumTime = length(Time)\nNumActions = length(Actions)\nNumStates = length(States)\n\n#functions\nPFPredict <- function(t0, pred.window, Xi_1, Ppolicy, Roadload, action_list, facility_length) {\n  upper.time <- pred.window+2\n  x_sample <- array(0,dim=c(dim(Xi_1),upper.time))\n  u_sample <- array(0,dim=c(dim(Xi_1),upper.time))\n  #P_traj_transit <- array(0,dim=c(dim(Xi_1),upper.time))\n  Xi_2 <- array(0,dim=dim(Xi_1))\n  Xi_3 <- array(0,dim=dim(Xi_1))\n  x_sample[,,1] <- Xi_1\n  for(i in c(2:upper.time)) {\n    t <- t0+i-2\n    print(t)\n    Xi_2[,] <- 0\n    Xi_3[,] <- 0\n    \n    xyz <- matrix(runif(length(Xi_1)), nrow=nrow(Xi_1))\n    AccumPpolicy <- Ppolicy[[t]]\n    AccumPpolicy <- lapply(AccumPpolicy, cumsum)\n    Xi_2 <- SamplingAction(Xi_1, xyz, AccumPpolicy, action_list)\n\n    #n_cur <- t(apply(Xi_1,1,function(x) table(factor(x, levels=c(1:length(locations))))))\n    n_cur <- t(apply(Xi_1,1,function(x) tabulate(x,nbins = length(locations))))\n    TimeMoveOut <- t(apply(n_cur[,(facility_length+1):ncol(n_cur)], 1, function(x) x/Roadload$Roadload*Roadload$TimeMoveOut))\n    for (j in c(1:ncol(TimeMoveOut))) {\n      TimeMoveOut[,j] <- pmax(TimeMoveOut[,j],Roadload$TimeMoveOut[j])\n    }\n    Pmoveout <- 1/TimeMoveOut\n    Pfacility = array(1,dim = c(nrow(Pmoveout),facility_length))\n    Ptransit = cbind(Pfacility,Pmoveout)\n    \n    xyz <- matrix(runif(length(Xi_1)), nrow=nrow(Xi_1))\n    Xi_3 <- SamplingState(Xi_1, Xi_2, xyz, Ptransit)\n    \n    #P_traj_transit[,,i-1] <- StateProb(Xi_1,Xi_2,Xi_3,Ptransit)\n    u_sample[,,i-1] <- Xi_2\n    x_sample[,,i] <- Xi_3\n    Xi_1 <- Xi_3\n  }\n  #P_traj_transit=P_traj_transit[,,1:(upper.time-1)]\n  return(list(u_sample=u_sample[,,1:(upper.time-1)],x_sample=x_sample[,,1:(upper.time-1)]))\n}\n\n#t_cur < 24*60, todo: 1. ensure no f to different f, 2. currently no duration 3. l-l to which facility?\nRewardFunction <- function(state.origin,t_cur,info_facility,goal_facility,facility_index,facility_length) {\n  home <- 1\n  leis <- 2\n  other <- 3\n  work <- 4\n  shop <- 5\n  BETA_late.ar <- -18\n  BETA_early.dp <- -1\n  #BETA_wait <- 0\n  BETA_short.dur <- 0\n  BETA_dur <- 6 #staying in goal facility\n  t_0.q <- 2\n  C_mode.q = 0\n  BETA_m = 1\n  BETA_trav.modeq = -6\n  \n  if ((t_cur/60 > info_facility$begin[[goal_facility]]) && (t_cur/60 < info_facility$end[[goal_facility]]) && (!(state.origin %in% facility_index$work)) && (goal_facility == work)) {\n    mid <- (info_facility$begin[[goal_facility]] + info_facility$end[[goal_facility]])/2\n    if (t_cur/60 < mid) {\n      S_late.ar.q <- BETA_late.ar\n      S_early.dp.q <- 0\n    } else {\n      S_late.ar.q <- 0\n      S_early.dp.q <- BETA_early.dp\n    }\n  } else if (((t_cur/60 > info_facility$begin[[goal_facility]]) || (t_cur/60 < info_facility$end[[goal_facility]])) && (!(state.origin %in% facility_index$home)) && (goal_facility == home)) {\n    mid <- (info_facility$begin[[goal_facility]] + info_facility$end[[goal_facility]])/2\n    if (t_cur/60 > mid) {\n      S_late.ar.q <- BETA_late.ar\n      S_early.dp.q <- 0\n    } else {\n      S_late.ar.q <- 0\n      S_early.dp.q <- BETA_early.dp\n    }\n  } else {\n    S_late.ar.q <- 0\n    S_early.dp.q <- 0\n  }\n  \n  #usefule working time: f-f, l-f\n  if (state.origin %in% facility_index[[goal_facility]]) {\n    S_dur.q <- BETA_dur\n  } else {\n    S_dur.q <- 0 \n  }\n  \n  #four cases: f-f, f-l, l-f, l-l\n  if(state.origin <= facility_length) {\n    #f-f, f-l\n    S_act.q <- S_dur.q + S_late.ar.q + S_early.dp.q\n    S_trav.q <- 0\n  } else {\n      #l-f, l-l\n      S_act.q <- S_late.ar.q + S_early.dp.q\n      S_trav.q <- C_mode.q + BETA_trav.modeq\n  }\n  S_plan <- S_act.q + S_trav.q\n  return(S_plan)\n}\n\nRewardTrajectoryFunction <- function(Xi_1, x_sample, info_facility, t_cur, goal_facility,facility_index,facility_length) {\n  S_plan <- array(0,dim=dim(x_sample))\n  for (i in c(1:dim(x_sample)[1])) {\n    print(i)\n    for (j in c(1:dim(x_sample)[2])) {\n      for (k in c(1:dim(x_sample)[3])) {\n        t <- t_cur +k - 1\n        state.origin <- x_sample[i,j,k]\n        S_plan[i,j,k] <- RewardFunction(state.origin,t,info_facility,goal_facility[k],facility_index,facility_length)\n      }\n      S_plan[i,j,] <- cumsum(S_plan[i,j,]) \n    }\n  }\n  return (S_plan)\n}\n\nGoalFacility <- function(length,t_cur,info_facility) {\n  home <- 1\n  leis <- 2\n  other <- 3\n  work <- 4\n  shop <- 5\n  goal_facility <- array(0,dim=length)\n  for (i in c(1:length(goal_facility))) {\n    tt <- t_cur+i-1\n    if ((tt/60>info_facility$begin[[work]])&&(tt/60<info_facility$end[[work]])) {\n      goal_facility[i] <- work\n    } else {\n      goal_facility[i] <- home\n    } \n  }\n  return(goal_facility)\n}\n\nlappend <- function (lst, ...){\n  lst <- c(lst, list(...))\n  return(lst)\n}\n\n#add <- function(x) Reduce(\"+\", x)\n\n# RL\ntime.th = min(td)/60-1\npred.window = 120\nmoving.step = 90\nobs.scale = 10\ntot_iter = 5\ntot_T = 1e1\ngamma = 0.998\ndelta = 0.999\nalpha_k = 0.5\na<-function(t) (1-delta)*delta^t\nb<-function(t) (1-gamma/delta)*(gamma/delta)^t\n\nt0.min = 181\nt0.max = 360\nt0 = t0.min\n#t0.max = trunc((nrow(Xt_real)-1)/pred.window)*pred.window\nXt_est[t0,] = rep(Yt[t0,],each=(obs.scale+1))[1:ncol(person.state.d)]\nwhile(t0 < t0.max) {\n  cat(sprintf('current time: %i\\n',t0))\n  iter = 1\n  if (TEST) {\n    x_model = array(0,dim=c(tot_iter,tot_T,ncol(person.state.d),pred.window+1))\n    r_model = array(0,dim=c(tot_iter,tot_T,ncol(person.state.d),pred.window+1)) \n  }\n  while (iter <= tot_iter) {\n    cat(sprintf('t0 = %i, iter = %i\\n',t0,iter))\n    # 1.sample T\n    time.period = c(1:pred.window)\n    T = sample(time.period,tot_T,replace = TRUE,prob = a(time.period))\n    \n    # 2. sample trejectories\n    print('sample trajectories')\n    Xi_1 = matrix(rep(Xt_est[t0,],each=tot_T),nrow=tot_T)\n    sample_trajectory = PFPredict(t0,pred.window,Xi_1,Ppolicy,Roadload,action_list,facility_length)\n    x_sample = sample_trajectory$x_sample\n    u_sample = sample_trajectory$u_sample\n    \n    # 3. computing weights\n    print('computing weights')\n    t_cur = t0+time.th\n    goal_facility = GoalFacility(dim(x_sample)[3],t_cur,info_facility)\n    r_sample = RewardTrajectoryFunction(Xi_1, x_sample, info_facility, t_cur, goal_facility,facility_index,facility_length)\n    r_prob = (r_sample-min(r_sample)+1)\n    r_prob = r_prob/max(r_prob)\n    w = array(0,dim=dim(r_prob)[1:2])\n    w = r_prob[,,pred.window+1]\n    \n    # 4. update F\n    print('update F')\n    action_percent = list()\n    \n    sourceCpp(\"rcpp_pf_location.cpp\")\n    load('data_exec/policy_template.RData')\n    for (k in c(1:(pred.window+1))) {\n      print(k)\n      tmp_count = ListCountAction3(x_sample[,,k],u_sample[,,k],w,policy_template,action_list)\n      tmp_list <- lapply(tmp_count, function(x) x/sum(x))\n      action_percent <- lappend(action_percent,tmp_list)\n    }\n    action_percent = rapply( action_percent, f=function(x) ifelse(is.nan(x),0,x), how=\"replace\" )\n    for (i in c(t0:(t0+pred.window))) {\n      Ppolicy[[i]] = ListAdd(Ppolicy[[i]],action_percent[[i-t0+1]],alpha_k)\n      Ppolicy[[i]] = lapply(Ppolicy[[i]], function(x) x/sum(x))\n    }\n    \n    # test\n    if (TEST) {\n      r_model[iter,,,] = r_sample\n      x_model[iter,,,] = x_sample\n      title = paste('SMA pf result',iter,sep='@')\n      SMA_scale = 10\n      Xt_est_vehicles = t(apply(x_sample[1,,],2,function(x) table(factor(x, levels=c(1:length(locations))))))\n      Xt_real_vehicles = t(apply(Xt_real,1,function(x) table(factor(x, levels=c(1:length(locations))))))\n      others = c(2,3,4,5,7,8,9,10)+2\n      vehicle_others_gt = apply(Xt_real_vehicles[,others], 1, sum)\n      vehicle_others_est = apply(Xt_est_vehicles[,others], 1, sum)\n      print(vehicle_others_est)\n      plot_lane = 2\n      plot(Xt_real_vehicles[,plot_lane],type='l',xlab='time',ylab='Vechiles',main=title,ylim = c(0,2000))\n      cl = rainbow(3)\n      lines(Xt_real_vehicles[,8],type='l',col='black')\n      lines(c(t0:(t0+pred.window)),Xt_est_vehicles[,2],type='l',col=cl[1])\n      lines(c(t0:(t0+pred.window)),Xt_est_vehicles[,8],type='l',col=cl[2])\n      lines(c(t0:(t0+pred.window)),vehicle_others_est,type='l',col=cl[3])\n      legend('topright',legend=c('gt@w','gt@6','est@w','est@6','est_others'),lty=array(1,dim=5),col=c('black','black',cl))\n      file.name = paste(title,'png',sep='.')\n      dev.copy(file=file.name, device=png, width=1024, height=768)\n      dev.off()\n      if(FALSE) {\n        test_time = pred.window\n        apply(apply(r_model[,,,test_time],c(1,2),sum),1,mean)\n        x_end=trunc(t(apply(x_model[,,,test_time], 1, function (x) table(factor(x,levels = c(1:length(locations))))))/dim(x_model)[2])\n        colnames(x_end) = locations\n        x_end\n      }\n    }\n    iter = iter + 1\n  }\n  \n  # 5. Simulation\n  print('simulation')\n  #improved policy\n  Xi_1 = matrix(rep(Xt_est[t0,],each=tot_T),nrow=tot_T)\n  sample_trajectory = PFPredict(t0,pred.window,Xi_1,Ppolicy,Roadload,action_list,facility_length)\n  x_sample = sample_trajectory$x_sample\n  u_sample = sample_trajectory$u_sample\n  t_cur = t0+time.th\n  goal_facility = GoalFacility(dim(x_sample)[3],t_cur,info_facility)\n  r_sample = RewardTrajectoryFunction(Xi_1, x_sample, info_facility, t_cur, goal_facility,facility_index,facility_length)\n  system.reward.updated = append(system.reward.updated,mean(r_sample[,,length(pred.window)]))\n  Xt_est[t0:(t0+moving.step),] = t(x_sample[1,,1:(moving.step+1)])\n  t0 = t0 + moving.step\n}\n\nStatisticsVehicles <- function(real.time, Xt_est_1,message,facility_index, t0) {\n  #Xt_est_1=Xt_real_1[t0.min:t0.max,]\n  Xt_athome <- apply(Xt_est_1[,facility_index$home], 1, sum)\n  Xt_atleis <- apply(Xt_est_1[,facility_index$leis], 1, sum)\n  Xt_atother <- apply(Xt_est_1[,facility_index$other], 1, sum)\n  Xt_atwork <- apply(Xt_est_1[,facility_index$work], 1, sum)\n  Xt_atshop <- apply(Xt_est_1[,facility_index$shop], 1, sum)\n  Xt_facilities_not_home <- Xt_atleis + Xt_atother + Xt_atshop + Xt_atwork\n  Xt_onroad <- apply(Xt_est_1, 1, sum) - Xt_athome - Xt_atleis - Xt_atother - Xt_atwork - Xt_atshop\n  title <- paste('Vehicle Distribution',message,sep='@')\n  plot(real.time/60,Xt_athome,type='l',col='red',main = title,ylim = c(0,max(Xt_athome)))\n  lines(real.time/60,Xt_atwork,type='l',col='blue')\n  lines(real.time/60,Xt_onroad,type='l',col='green')\n  abline(v=info_facility$begin[[4]],col='gray')\n  legend('topright',legend=c('vehicles at home','vehicles at work', 'vehicles on roads'),lty=array(1,dim=3),col=c('red','blue','green'))\n  file.name <- paste(title,'png',sep='.')\n  dev.copy(file=file.name, device=png, width=1024, height=768)\n  dev.off()\n  time <- c(0,10,30,60,120)\n  result <- Xt_atwork[ceiling(info_facility$begin[[2]]*60-time.th+time-t0)]/2000\n  return(result)\n}\n\n'%!in%' <- function(x,y)!('%in%'(x,y))\n\n#Comparing statistics\nif (TRUE) {\n  real.time = c(t0.min:t0.max) + time.th\n  t0 = t0.min\n  # updated policy\n  if (TRUE) {\n    Xt_est_updated = t(apply(Xt_est[c(t0:(t0+length(real.time)-1)),], 1, function(x) tabulate(x,nbins = dim(Yt_vehicles)[2])))\n    percentage.ontime.updated = StatisticsVehicles(real.time, Xt_est_updated, 'updated', facility_index, t0)\n    #home to work\n    tmp1 = apply(Xt_est[c(t0:(t0+length(real.time)-1)),], 2, function(x) which(x %!in% facility_index$home)[1])\n    tmp2 = apply(Xt_est[c(t0:(t0+length(real.time)-1)),], 2, function(x) which(x %in% facility_index$work)[1])\n    Xt_time_updated = tmp2 - tmp1\n    Xt_time_updated[is.na(Xt_time_updated)] = 0\n    cat(sprintf('updated work on time percetage : %f\\n',percentage.ontime.updated))\n    cat(sprintf('updated average time on road h->w : %f\\n',sum(c(Xt_time_updated))/length(which(Xt_time_updated>0))))\n    cat(sprintf('updated system reward: %e\\n',mean(unlist(system.reward.updated))))\n  }\n  # original\n  if (TRUE) {\n    Xi_1 = matrix(rep(Xt_est[t0,],each=tot_T),nrow=tot_T)\n    sample_trajectory = PFPredict(t0,t0.max-t0.min,Xi_1,policy_origin,Roadload,action_list,facility_length)\n    x_sample = sample_trajectory$x_sample\n    u_sample = sample_trajectory$u_sample\n    t_cur = t0+time.th\n    goal_facility = GoalFacility(dim(x_sample)[3],t_cur,info_facility)\n    r_sample = RewardTrajectoryFunction(Xi_1, x_sample, info_facility, t_cur, goal_facility,facility_index,facility_length)\n    system.reward.original = mean(r_sample[,,length(real.time)])\n    \n    Xt_est_original_all = apply(x_sample, c(1,3), function(x) tabulate(x,nbins = dim(Yt_vehicles)[2]))\n    Xt_est_original = t(apply(Xt_est_original_all, c(1,3), mean))\n    percentage.ontime.original = StatisticsVehicles(real.time, Xt_est_original, 'original', facility_index, t0)\n    #home to work\n    tmp1 = apply(x_sample, c(1,2), function(x) which(x %!in% facility_index$home)[1])\n    tmp2 = apply(x_sample, c(1,2), function(x) which(x %in% facility_index$work)[1])\n    Xt_time_original = tmp2 - tmp1\n    Xt_time_original[is.na(Xt_time_original)] = 0\n    cat(sprintf('original work on time percetage : %f\\n',percentage.ontime.original))\n    cat(sprintf('original average time on road h->w : %f\\n',sum(c(Xt_time_original))/length(which(Xt_time_original>0))))\n    cat(sprintf('original system reward: %e\\n',system.reward.original))\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1478108102657.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3791682357",
    "id" : "DCDE1A9C",
    "lastKnownWriteTime" : 1478976560,
    "last_content_update" : 1518050401918,
    "path" : "~/Documents/R/RL_DrivePlan_0/Berlin/bench_berlin5_100/exec3_largeSenario.R",
    "project_path" : "exec3_largeSenario.R",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}